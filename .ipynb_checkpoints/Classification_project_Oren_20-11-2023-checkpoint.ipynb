{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab82ae3-2056-4d0a-b9bb-41381ae2b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20-11-2023, Oren - Classification Project Notebook\n",
    "# Re-Starting using existing sklearn pre-processing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f07b91-371e-4668-a32f-ba9ec368cd81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, \\\n",
    "    AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve, recall_score, precision_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def csv_drive_path_generatoer(url):\n",
    " '''\n",
    " Help in read csv file directly from google drive.\n",
    " Make sure the csv format is standard.\n",
    " url:str - path to csv file example:\n",
    "   url = 'https://drive.google.com/file/d/126JPZ3lYwdLyJ2d_7jxM9jMtZaOlF-Ld/view?usp=sharing'\n",
    " return : str\n",
    " '''\n",
    " path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
    " return path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c28e4a5-0242-4a36-9429-a61ce55dee8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "link_X_train = 'https://drive.google.com/file/d/11Dgctv-N6z3ugQOpRrFNKVP5NNqPPWxK/view?usp=drive_link'\n",
    "link_y_train = 'https://drive.google.com/file/d/1NDF2aCymR4zjYK9mLYNRwIdB_EyE5ZHl/view?usp=drive_link'\n",
    "\n",
    "link_X_test = 'https://drive.google.com/file/d/1ZRg80tYdBO1pcd_6R1m_tiijZSfDXMZ6/view?usp=drive_link'\n",
    "\n",
    "path_X_train = csv_drive_path_generatoer(link_X_train)\n",
    "path_y_train = csv_drive_path_generatoer(link_y_train)\n",
    "\n",
    "path_X_test = csv_drive_path_generatoer(link_X_test)\n",
    "\n",
    "X_train = read_csv(path_X_train, index_col = 0)\n",
    "y_train = read_csv(path_y_train, index_col = 0)\n",
    "\n",
    "train_data = X_train.join(y_train).set_index('id')\n",
    "\n",
    "X_test = read_csv(path_X_test, index_col = 0)\n",
    "y_test_dummy = pd.DataFrame(data = np.zeros(len(X_test.index)), index = X_test.index, dtype = 'int64', columns = ['y_test_dummy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3a6a37-1630-4b90-b63a-434c8fc414ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mjoin(y_train)\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.join(y_train).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d980fb-124c-49e2-ae08-d6de5e5ed62d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define custom transformer for feature engineering and dropping of null values\n",
    "\n",
    "class FeatureEngineerAndNullsDropper(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X_and_y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_and_y, new_feature = 'Tenure', current_year = 2023):\n",
    "        # Check if 'JoiningYear' is present in the input data\n",
    "        if 'JoiningYear' not in data.columns:\n",
    "            raise ValueError(\"Column 'JoiningYear' not found in input data.\")\n",
    "            \n",
    "        # Feature engineering logic here\n",
    "        X_and_y[new_feature] = current_year - X['JoiningYear']\n",
    "        X_and_y = X_and_y.drop(['JoiningYear'], axis = 1)\n",
    "        \n",
    "        # drop null values\n",
    "        return X_and_y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621c541-633a-4948-9349-4f4e142552a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mastery code...\n",
    "# define model\n",
    "# model = LogisticRegression()\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Specify the order of categories for the 'Education' feature\n",
    "Education_order = ['Bachelors', 'Masters', 'PHD']\n",
    "\n",
    "# Create transformers for different types of features\n",
    "FeatureEngineerAndNullsDropper_features = ['JoiningYear']\n",
    "ordinal_category_features = ['Education']\n",
    "non_binary_categorical_features = ['City', 'Race']\n",
    "binary_categorical_features = ['Gender','EverBenched'] \n",
    "\n",
    "# Create transformers for different types of features\n",
    "nulls_droper_engineer_transformer = [('FeatureEngineerAndNullsDropper', FeatureEngineerAndNullsDropper(), FeatureEngineerAndNullsDropper_features)]\n",
    "binary_categorical_transformer = [('binary', OneHotEncoder(drop='if_binary'), binary_categorical_features)]\n",
    "non_binary_categorical_transformer = [('non_binary', OneHotEncoder(), non_binary_categorical_features)]\n",
    "ordinal_transformer = [('ordinal', OrdinalEncoder(categories=[Education_order]), ordinal_category_features)]\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('nulls_droper_engineer',nulls_droper_engineer_transformer, FeatureEngineerAndNullsDropper_features),\n",
    "        ('binary_cat', binary_categorical_transformer, binary_categorical_features),\n",
    "        ('non_binary_cat', non_binary_categorical_transformer, non_binary_categorical_features),\n",
    "        ('ordinal_cat', ordinal_transformer, ordinal_category_features)\n",
    "    ],\n",
    "    remainder='passthrough') # passthrough all columns not explicitly transformed\n",
    "\n",
    "# Assuming 'data' is your input DataFrame\n",
    "trans_X_and_y_train = column_transformer.fit_transform(X_and_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a41ca-1394-40be-b01f-c2d3257f6504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbb122-0ba8-4830-b431-7ddc415a418e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea6c00e-64a5-40fb-a0a5-83f99d12637a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89a779-b77e-48b2-84cf-a0a96c37a7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ce1be-76a3-4fe5-af4c-3ef7ecb0cd02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3f2f6-4199-49c2-8b8f-9ba5547f6aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169cb5e-66ae-4fde-a12b-4c271e52f220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4526c-82dd-4168-be41-32fbfb0ddb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689dfc5-0e07-462e-9a3e-e8f5f4f081bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e825928-d740-47eb-87ef-4ff339804486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(X_train, X_test, y_train, y_test, ensemble_classifier):\n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "    # clf = DecisionTreeClassifier()\n",
    "    # model_a_bagging = BaggingClassifier(estimator = base_model, n_estimators= 100)\n",
    "\n",
    "    # fitting the models\n",
    "    ensemble_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # predict probabilities\n",
    "    probas = ensemble_classifier.predict_proba(X_test)\n",
    "\n",
    "    # keep probabilities for the positive outcome only\n",
    "    probas = probas[:,1]\n",
    "\n",
    "    # calculate rocs auc scores\n",
    "    auc = roc_auc_score(y_test, probas)\n",
    "\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs, pos_label = 1)\n",
    "    fpr, tpr, _ = roc_curve(y_test, probas, pos_label = 1)\n",
    "\n",
    "    # plot the roc curve for the model\n",
    "\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(fpr, tpr, marker='.', label=f\"{ensemble_classifier}, auc = {auc:.3f}\")\n",
    "\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "\n",
    "    # show the legend\n",
    "    plt.legend(fontsize = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79722a1a-6fc5-42c0-a3da-71d6ae66dc77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roc_curve(X_train, X_test, y_train, y_test, BaggingClassifier(estimator = DecisionTreeClassifier(max_depth = 7), n_estimators = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b8b56a-41fc-4382-9087-c6e05ad3bc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_adaboost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 7), n_estimators = 100,\n",
    "                                  learning_rate=0.01)\n",
    "clf_adaboost.fit(X_train, y_train)\n",
    "print(f\"DT ADA boosting classifier:\\n \\\n",
    "    \\ttrain accuracy: {clf_adaboost.score(X_train, y_train):.2f}\\n \\\n",
    "    \\ttest accuracy: {clf_adaboost.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265be20-86fa-4fa6-9df8-3a84710c0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc47473-f9d6-4c26-9b02-e7f2a7ced8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ca439-d1d8-4473-b9d2-cd2068882b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a5c7b-e460-4e90-be41-87c0dfc0b43b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rfc = RandomForestClassifier()\n",
    "# rfc_params = {'max_depth': [5,10,15,20,40,100], 'max_features': [2,3,4,5,6,7,8,9]}\n",
    "# gs_rfc = GridSearchCV(rfc, rfc_params, cv = 5, scoring='accuracy')\n",
    "# gs_rfc.fit(X_train, y_train)\n",
    "# print(gs_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7f736-54b5-4b94-85d2-5735eceac98a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gs_rfc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057d761-1c21-4b0e-9283-9c11c2c7024d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bagging_clf = BaggingClassifier(estimator = DecisionTreeClassifier(max_depth = 7))\n",
    "bag_params = {'bootstrap': [True,False], 'bootstrap_features': [False,True],\\\n",
    "              'max_features': [6,7,8],\n",
    "                'oob_score': [True,False],\n",
    "                 'warm_start': [True]}\n",
    "\n",
    "\n",
    "gs_bag = GridSearchCV(bagging_clf, bag_params, cv = 5, scoring = 'f1')\n",
    "gs_bag.fit(X_train, y_train)\n",
    "gs_bag.best_score_\n",
    "\n",
    "# bagging_clf.get_params()\n",
    "# bagging_params = {'max_depth': [5,10,15,20,40,100], 'max_features': [2,3,4,5,6,7,8,9]}\n",
    "# gs_rfc = GridSearchCV(rfc, rfc_params, cv = 5, scoring='f1')\n",
    "# gs_rfc.fit(X_train, y_train)\n",
    "# print(gs_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f03e7c-2917-45be-94c1-b8e1e519d689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gs_bag.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90b269-73ad-4a71-b489-b694546352d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BaggingClassifier(estimator = DecisionTreeClassifier(max_depth = 7), n_estimators = 100).get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fded26-e62e-479e-9a02-cd92dc08fb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4728a9c-1e2e-423c-ac67-d6d8c796a990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74fde1-9796-425d-a4ca-2880b76b25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# import scipy.stats as stats\n",
    "\n",
    "# Define the hyperparameter distributions\n",
    "param_dist = {\n",
    "    'max_depth': stats.randint(3, 10),\n",
    "    'learning_rate': stats.uniform(0.00001, 0.01),\n",
    "    'subsample': stats.uniform(0.5, 0.5),\n",
    "    'n_estimators':stats.randint(50, 200)\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211e3d6-d435-4f26-b7b9-f6e0d6cffecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, \\\n",
    "    AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "f1s, precisions, recalls, accuracies, classifiers_as_str = [],[],[],[], []\n",
    "features, i_s = [], []\n",
    "# classifiers = [XGBClassifier(learning_rate = 0.009956053586134729, max_depth = 6, n_estimators = 76, subsample = 0.6838981373746974), AdaBoostClassifier,\\\n",
    "#             KNeighborsClassifier(), LogisticRegression(), DecisionTreeClassifier(), GradientBoostingClassifier(), RandomForestClassifier()]\n",
    "\n",
    "classifiers = [DecisionTreeClassifier(),KNeighborsClassifier(), LogisticRegression(),GradientBoostingClassifier(), RandomForestClassifier(),\\\n",
    "               AdaBoostClassifier(),XGBClassifier(learning_rate = 0.01, max_depth = 7, n_estimators = 100, subsample = 0.786)]\n",
    "              \n",
    "for classifier in classifiers:\n",
    "    # for i in range(1,len(feature_imp)+1):\n",
    "    #     X_train = X_train[feature_imp[:i]]\n",
    "    #     X_train.columns = [feature_imp[:i]\n",
    "    #     # X_test = X_test[feature_imp[:i]]\n",
    "    #     print(X_train)\n",
    "    #     # print(X_test)\n",
    "        \n",
    "    model = classifier\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test,y_test_pred)\n",
    "    recall = recall_score(y_test, y_test_pred)\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    f1s.append(f1.round(3))\n",
    "    precisions.append(precision.round(3))\n",
    "    recalls.append(recall.round(3))\n",
    "    accuracies.append(accuracy.round(3))\n",
    "    # i_s.append(i)\n",
    "    classifiers_as_str.append(str(classifier).split('(')[0])\n",
    "\n",
    "report = pd.DataFrame({'classifier': classifiers_as_str,'accuracy': accuracies, 'recall':recalls,'precision':precisions,'f1_score': f1s})\n",
    "print(report.sort_values(by = 'f1_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9d3e4-8f4c-4b1e-b0c0-bc13452273c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect the XGBClassifer confusion matrix:\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "xgb_cm = pd.DataFrame(data = confusion_matrix(y_test, y_test_pred), index = target_names, columns = target_names)\n",
    "print(xgb_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9db12-ec5e-48a4-aed5-60e80e625663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do 17-11-2023 (Raz S):\n",
    "# 1. cm of the different models\n",
    "# 2. Actual vs. predicted probas\n",
    "# 3. Look at features of false positive vs. true positive\n",
    "# 4. Balance_classes (bool)\n",
    "# 5. Class weights (Loss handling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
